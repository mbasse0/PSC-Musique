{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3539f61f-fe7d-4428-b074-327a883f7f6e",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b84d27",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Vocab\n",
        "\n",
        "\n",
        "NOTE_SIZE = 128\n",
        "DUR_SIZE = 160\n",
        "TIM_SIZE = 1000\n",
        "VEL_SIZE = 128\n",
        "\n",
        "\n",
        "NOTE_TOKS = [f'n{i}' for i in range(NOTE_SIZE)] \n",
        "DUR_TOKS = [f'd{i}' for i in range(DUR_SIZE)]\n",
        "TIM_TOKS = [f't{i}' for i in range(TIM_SIZE)]\n",
        "VEL_TOKS = [f'v{i}' for i in range(VEL_SIZE)]\n",
        "\n",
        "BOS_TOK = \"BOS\"\n",
        "# Le token dummy sert seulement à initialiser les mots du vocab à partir de l'index 1, conformément aux prérequis de la fonction vocab()\n",
        "VOCAB = [\"dummy\"] + [BOS_TOK] + NOTE_TOKS + DUR_TOKS + TIM_TOKS + VEL_TOKS \n",
        "\n",
        "DICT = [(element, index) for index, element in enumerate(VOCAB)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1e4d23",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchtext.vocab import vocab\n",
        "from collections import OrderedDict\n",
        "\n",
        "custom_vocab = vocab(OrderedDict(DICT))\n",
        "itos_vocab = custom_vocab.get_itos()\n",
        "\n",
        "vocab_size = len(custom_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dfce226c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ArtPepper_Stardust-2_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1/13 [00:02<00:33,  2.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyCarter_IGotItBad_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 2/13 [00:04<00:22,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyCarter_It'sAWonderfulWorld-1_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 4/13 [00:05<00:09,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyCarter_It'sAWonderfulWorld-2_FINAL.mid\n",
            "BennyCarter_JustFriends_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 6/13 [00:06<00:03,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyCarter_LongAgoAndFarAway-1_FINAL.mid\n",
            "BennyCarter_LongAgoAndFarAway-2_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 7/13 [00:06<00:02,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyCarter_SweetLorraine_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 10/13 [00:07<00:00,  3.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyGoodman_Avalon_FINAL.mid\n",
            "BennyGoodman_HandfulOfKeys_FINAL.mid\n",
            "BennyGoodman_Nobody'sSweetheart_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:07<00:00,  5.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BennyGoodman_Runnin'Wild_FINAL.mid\n",
            "BennyGoodman_TigerRag-1_FINAL.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:07<00:00,  1.78it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from music21 import *\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the MIDI file\n",
        "midi_file = midi.MidiFile()\n",
        "\n",
        "les_tokens = []\n",
        "\n",
        "# Dossier contenant les fichiers MIDI pour l'entraînement\n",
        "folder_path = \"train_data\"  \n",
        "\n",
        "# Get all the file names in the folder\n",
        "file_names = os.listdir(folder_path)\n",
        "for f in tqdm(file_names):\n",
        "    print(f)\n",
        "    midi_file = midi.MidiFile()\n",
        "    midi_file.open(folder_path + \"/\" +f)\n",
        "    midi_file.read()\n",
        "    midi_file.close()\n",
        "    # Create a stream from the MIDI file\n",
        "    stream = midi.translate.midiFileToStream(midi_file)\n",
        "\n",
        "    # Iterate over the notes in the stream and extract the note information\n",
        "    last_time = 0\n",
        "\n",
        "    for note in stream.flat.notes:\n",
        "        if note.isNote:\n",
        "            note_pitch = note.pitch.midi\n",
        "            # A terme il faudra arrondir plutot que de prendre la partie entiere\n",
        "            note_duration = int(note.duration.quarterLength*4)\n",
        "            note_offset = int(note.offset*4 - last_time)\n",
        "            last_time = note.offset*4\n",
        "            note_velocity = note.volume.velocity\n",
        "            les_tokens.append(NOTE_TOKS[note_pitch])\n",
        "            les_tokens.append(DUR_TOKS[note_duration])\n",
        "            if note_offset < NOTE_SIZE:\n",
        "                les_tokens.append(TIM_TOKS[note_offset])\n",
        "            les_tokens.append(VEL_TOKS[note_velocity])\n",
        "\n",
        "        if note.isChord:\n",
        "\n",
        "            for note2 in note:\n",
        "                note_pitch = note2.pitch.midi\n",
        "                note_duration = int(note.duration.quarterLength*4)\n",
        "                note_offset = int(note.offset*4 - last_time)\n",
        "                last_time = note.offset*4\n",
        "                note_velocity = note2.volume.velocity\n",
        "                les_tokens.append(NOTE_TOKS[note_pitch])\n",
        "                les_tokens.append(DUR_TOKS[note_duration])\n",
        "                if note_offset < NOTE_SIZE:\n",
        "                    les_tokens.append(TIM_TOKS[note_offset])\n",
        "                les_tokens.append(VEL_TOKS[note_velocity])\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ef74fa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#répartir le data du morceau en blocs de 120 attributs (30 notes)\n",
        "#Et associer à chaque bloc la réponse attendue (l'attribut suivant)\n",
        "\n",
        "taille_bloc = 120\n",
        "les_morceaux = []\n",
        "les_morceaux_rep = []\n",
        "\n",
        "for i in range(len(les_tokens)//(taille_bloc+1)-1):\n",
        "    les_morceaux.append(les_tokens[i:i+taille_bloc-1])\n",
        "    les_morceaux_rep.append(les_tokens[i:i+taille_bloc])\n",
        "\n",
        "\n",
        "\n",
        "input_vect = [ [0] + [ custom_vocab[tok] for tok in morceau] for morceau in les_morceaux ]\n",
        "rep_vect = [ [ custom_vocab[tok] for tok in morceau] for morceau in les_morceaux_rep ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "10b3108a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Si on choisit de charger des fichiers enregistrés plutôt que faire le encoding\n",
        "input_vect = np.load('input_weimar.npy')\n",
        "rep_vect = np.load('rep_weimar.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d1b048b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Define the dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, input_data, output_data):\n",
        "        self.input_data = input_data\n",
        "        self.output_data = output_data    \n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        input_tensor = torch.tensor(self.input_data[idx], dtype=torch.long)\n",
        "        output_tensor = torch.tensor(self.output_data[idx], dtype=torch.long)\n",
        "        return input_tensor, output_tensor\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "dataset = MyDataset(input_vect, rep_vect)\n",
        "\n",
        "\n",
        "# Create a dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c72c2ada-2106-4505-82f5-086e518080a5",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c72c2ada-2106-4505-82f5-086e518080a5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "588b2729-866c-470a-aca7-6a3c5ea0b192"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "            batch_first = True\n",
        "        )\n",
        "        self.out1 = nn.Linear(dim_model, num_tokens)\n",
        "        self.out2 = nn.Linear(dim_model, num_tokens)\n",
        "        self.out3 = nn.Linear(dim_model, num_tokens)\n",
        "        self.out4 = nn.Linear(dim_model, num_tokens)\n",
        "\n",
        "    # A modifier pour utiliser 4 out functions différentes selon les cas    \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "        prev_token = tgt[:,-1]\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "\n",
        "        # Pour toutes les valeurs du batch size, on passe le résultat du transformer (de la taille de l'embeddding) dans la couche out adaptée afin d'obtenir un output final de la taille du vocab\n",
        "        for d in range(len(prev_token)):\n",
        "            type_tok = itos_vocab[prev_token[d]][0]\n",
        "            if type_tok =='n':\n",
        "                out = self.out1(transformer_out)\n",
        "            elif type_tok=='d':\n",
        "                out = self.out2(transformer_out)\n",
        "            elif type_tok=='t':\n",
        "                out = self.out3(transformer_out)\n",
        "            elif type_tok=='v':\n",
        "                out = self.out4(transformer_out)\n",
        "            \n",
        "        return out\n",
        "\n",
        "    # Genere un masque triangulaire  \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    # Le pad mask sera utile quand on aura ajouté les PAD tokens\n",
        "    # def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "    #     # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "    #     # [False, False, False, True, True, True]\n",
        "    #     return (matrix == pad_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(\n",
        "    num_tokens=len(custom_vocab), dim_model=512, num_heads=8, num_encoder_layers=1, num_decoder_layers=4, dropout_p=0.1\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model_file = \"model4out.pth\"\n",
        "\n",
        "# Load the pre-trained model\n",
        "state_dict = torch.load(model_file, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device)\n",
        "\n",
        "#On met le model en mode eval\n",
        "model.eval()\n",
        "\n",
        "\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8cedaea8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7bc6949f-2d59-44c3-8198-037e115106aa",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "\n",
        "    # Entraîner le modèle sur une boucle\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        y_input, y_expected = batch\n",
        "\n",
        "        # X est ce qu'on donne à l'encoder. Un vecteur nul dans notre cas en l'absence d'informations contextuelles\n",
        "        X = torch.tensor([0]*len(y_input)).to(device)\n",
        "        #X, y_input, y_expected = X.clone().detach().to(device) , y_input.clone().detach().to(device) , y_expected.clone().detach().to(device)\n",
        "        X, y_input, y_expected = X.to(device) , y_input.to(device) , y_expected.to(device) \n",
        "\n",
        "        \n",
        "        # Get mask to mask out the next words\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "        # Permute pred to have batch size first again\n",
        "        #pred = pred.permute(0, 2, 1)     \n",
        "        loss = loss_fn(pred[:,-1,:], y_expected[:,-1])\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "53082db0",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.35s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7.367593574523926"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# On vérifie qu'une boucle seule fonctionne\n",
        "#train_loop(model,opt, loss_fn,dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
        "outputId": "e60c13ed-f56f-42ce-b920-510e0c538a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model\n",
            "------------------------- Epoch 1 -------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/206 [04:03<00:00,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 2.7988\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list= []\n",
        "    \n",
        "    print(\"Training model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        #validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        #validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        #print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print()\n",
        "        \n",
        "    return train_loss_list#, validation_loss_list\n",
        "    \n",
        "train_loss_list = fit(model, opt, loss_fn, dataloader, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "40f805ad-7748-4785-9066-c5500287a4af",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "40f805ad-7748-4785-9066-c5500287a4af",
        "outputId": "be8896c7-a820-4525-a92a-d3d6da36216b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_loss_list, label = \"Train loss\")\n",
        "#plt.plot(validation_loss_list, label = \"Validation loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "58121982",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the model to a file\n",
        "torch.save(model.state_dict(), 'model4out.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ad32d02",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-3acbbb6ff37b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# i un indice dans notre dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tgt_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Testons le modèle\n",
        "# Les unsqueeze permettent d'adapter les shape (avec un batch_size de 1)\n",
        "\n",
        "# i un indice dans notre dataset\n",
        "i = 0\n",
        "y_input = dataset[i][0].unsqueeze(0).to(device)\n",
        "tgt_mask = model.get_tgt_mask(y_input[0].size(0)).to(device)\n",
        "pred = model(torch.tensor([0]*len(y_input[0])).unsqueeze(0).to(device), y_input, tgt_mask)\n",
        "next_item = pred.topk(1)[1].view(-1)[-1].item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8a7df926",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'n58'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Le token prédit est ...\n",
        "itos_vocab[next_item]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "3c5be43b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['d1',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v109',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v101',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v109',\n",
              " 'n63',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v113',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v109',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v109',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v113',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n60',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v112',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v101',\n",
              " 'n61',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v95',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v113',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n60',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v101',\n",
              " 'n61',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v109',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n62',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n60',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n60',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v101',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n58']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r1 = [itos_vocab[v] for v in pred.topk(1)[1].view(-1)]\n",
        "r1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "aff4797e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BOS',\n",
              " 'n65',\n",
              " 'd2',\n",
              " 'v104',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't4',\n",
              " 'v109',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v103',\n",
              " 'n61',\n",
              " 'd3',\n",
              " 't2',\n",
              " 'v104',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't4',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't5',\n",
              " 'v106',\n",
              " 'n58',\n",
              " 'd7',\n",
              " 't4',\n",
              " 'v98',\n",
              " 'n50',\n",
              " 'd2',\n",
              " 't39',\n",
              " 'v90',\n",
              " 'n57',\n",
              " 'd2',\n",
              " 't4',\n",
              " 'v113',\n",
              " 'n60',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v110',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v111',\n",
              " 'n55',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v103',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v106',\n",
              " 'n61',\n",
              " 'd4',\n",
              " 't1',\n",
              " 'v106',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't5',\n",
              " 'v112',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v100',\n",
              " 'n60',\n",
              " 'd5',\n",
              " 't2',\n",
              " 'v105',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't6',\n",
              " 'v109',\n",
              " 'n56',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v107',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v106',\n",
              " 'n59',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v101',\n",
              " 'n57',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v103',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v111',\n",
              " 'n54',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n55',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v97',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't1',\n",
              " 'v109',\n",
              " 'n61',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v107',\n",
              " 'n56',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v103',\n",
              " 'n61',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v113',\n",
              " 'n62',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v114']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# La séquence donnée en entrée était ...\n",
        "r2 = [itos_vocab[v] for v in y_input[0]]\n",
        "r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "846443af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['n65',\n",
              " 'd2',\n",
              " 'v104',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't4',\n",
              " 'v109',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v103',\n",
              " 'n61',\n",
              " 'd3',\n",
              " 't2',\n",
              " 'v104',\n",
              " 'n63',\n",
              " 'd2',\n",
              " 't4',\n",
              " 'v114',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't5',\n",
              " 'v106',\n",
              " 'n58',\n",
              " 'd7',\n",
              " 't4',\n",
              " 'v98',\n",
              " 'n50',\n",
              " 'd2',\n",
              " 't39',\n",
              " 'v90',\n",
              " 'n57',\n",
              " 'd2',\n",
              " 't4',\n",
              " 'v113',\n",
              " 'n60',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v110',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v111',\n",
              " 'n55',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v103',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v106',\n",
              " 'n61',\n",
              " 'd4',\n",
              " 't1',\n",
              " 'v106',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't5',\n",
              " 'v112',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v100',\n",
              " 'n60',\n",
              " 'd5',\n",
              " 't2',\n",
              " 'v105',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't6',\n",
              " 'v109',\n",
              " 'n56',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v107',\n",
              " 'n60',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v106',\n",
              " 'n59',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v101',\n",
              " 'n57',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v103',\n",
              " 'n58',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v111',\n",
              " 'n54',\n",
              " 'd2',\n",
              " 't2',\n",
              " 'v102',\n",
              " 'n55',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v97',\n",
              " 'n58',\n",
              " 'd1',\n",
              " 't1',\n",
              " 'v109',\n",
              " 'n61',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v107',\n",
              " 'n56',\n",
              " 'd1',\n",
              " 't3',\n",
              " 'v103',\n",
              " 'n61',\n",
              " 'd2',\n",
              " 't1',\n",
              " 'v113',\n",
              " 'n62',\n",
              " 'd1',\n",
              " 't2',\n",
              " 'v114',\n",
              " 'n58']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Et la target\n",
        "r3 = [itos_vocab[v] for v in dataset[i][1].unsqueeze(0).to(device)[0]]\n",
        "r3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "8d8eee4b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "res = 0\n",
        "for j in range(len(r1)):\n",
        "    if (r1[j]==r3[j]):\n",
        "        res +=1\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56c3cc9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the datset arrays to a file\n",
        "np.save('input_weimar_test.npy', input_vect)\n",
        "np.save('rep_weimar_test.npy', rep_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5c5c0b61",
      "metadata": {},
      "outputs": [],
      "source": [
        "#sauver la prédiction\n",
        "\n",
        "np.save('pred_test.npy', pred.topk(1)[1].view(-1).cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b82b58c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "#sauver la prédiction\n",
        "\n",
        "np.save('morceau_test.npy', dataset[i][1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Inference",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "62c874bf93cba6215fcbca84adbfbe32b2ca0e29f0c7e59c6c1a61786fb9dcf2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
