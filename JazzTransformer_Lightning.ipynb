{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lighthing as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocab\n",
    "\n",
    "\n",
    "NOTE_SIZE = 128\n",
    "DUR_SIZE = 160\n",
    "TIM_SIZE = 1000\n",
    "VEL_SIZE = 128\n",
    "\n",
    "\n",
    "NOTE_TOKS = [f'n{i}' for i in range(NOTE_SIZE)] \n",
    "DUR_TOKS = [f'd{i}' for i in range(DUR_SIZE)]\n",
    "TIM_TOKS = [f't{i}' for i in range(TIM_SIZE)]\n",
    "VEL_TOKS = [f'v{i}' for i in range(VEL_SIZE)]\n",
    "\n",
    "BOS_TOK = \"BOS\"\n",
    "# Le token dummy sert seulement à initialiser les mots du vocab à partir de l'index 1, conformément aux prérequis de la fonction vocab()\n",
    "VOCAB = [\"dummy\"] + [BOS_TOK] + NOTE_TOKS + DUR_TOKS + TIM_TOKS + VEL_TOKS \n",
    "\n",
    "DICT = [(element, index) for index, element in enumerate(VOCAB)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import OrderedDict\n",
    "\n",
    "custom_vocab = vocab(OrderedDict(DICT))\n",
    "itos_vocab = custom_vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from music21 import *\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the MIDI file\n",
    "midi_file = midi.MidiFile()\n",
    "\n",
    "les_tokens = []\n",
    "\n",
    "# Dossier contenant les fichiers MIDI pour l'entraînement\n",
    "folder_path = \"train_data\"  \n",
    "\n",
    "# Get all the file names in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "for f in tqdm(file_names):\n",
    "    print(f)\n",
    "    midi_file = midi.MidiFile()\n",
    "    midi_file.open(folder_path + \"/\" +f)\n",
    "    midi_file.read()\n",
    "    midi_file.close()\n",
    "    # Create a stream from the MIDI file\n",
    "    stream = midi.translate.midiFileToStream(midi_file)\n",
    "\n",
    "    # Iterate over the notes in the stream and extract the note information\n",
    "    last_time = 0\n",
    "\n",
    "    for note in stream.flat.notes:\n",
    "        if note.isNote:\n",
    "            note_pitch = note.pitch.midi\n",
    "            # A terme il faudra arrondir plutot que de prendre la partie entiere\n",
    "            note_duration = int(note.duration.quarterLength*4)\n",
    "            note_offset = int(note.offset*4 - last_time)\n",
    "            last_time = note.offset*4\n",
    "            note_velocity = note.volume.velocity\n",
    "            les_tokens.append(NOTE_TOKS[note_pitch])\n",
    "            les_tokens.append(DUR_TOKS[note_duration])\n",
    "            les_tokens.append(TIM_TOKS[note_offset])\n",
    "            les_tokens.append(VEL_TOKS[note_velocity])\n",
    "\n",
    "        if note.isChord:\n",
    "\n",
    "            for note2 in note:\n",
    "                note_pitch = note2.pitch.midi\n",
    "                note_duration = int(note.duration.quarterLength*4)\n",
    "                note_offset = int(note.offset*4 - last_time)\n",
    "                last_time = note.offset*4\n",
    "                note_velocity = note2.volume.velocity\n",
    "                les_tokens.append(NOTE_TOKS[note_pitch])\n",
    "                les_tokens.append(DUR_TOKS[note_duration])\n",
    "                les_tokens.append(TIM_TOKS[note_offset])\n",
    "                les_tokens.append(VEL_TOKS[note_velocity])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
